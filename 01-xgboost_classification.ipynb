{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f7e9e-0db9-42de-8459-5c2a5c920ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5c4f4-26c2-4568-8b57-b3e5e1e80ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, random, math, time, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "import uuid\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import iqr\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72075fc7-8114-4078-9d0a-29ed611b818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qDir = r\"./QUANT_v4\"\n",
    "qFiles = glob.glob(os.path.join(qDir,\"*_QUANT.tsv\"))\n",
    "#pprint(qFiles)\n",
    "print(\"Found \"+str(len(qFiles))+\" Quant Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be15813-4110-4f68-8820-cb41104c995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepDFList = []\n",
    "for qFile in qFiles:\n",
    "    fhNom = os.path.basename(qFile)\n",
    "    if \"tonsil\" in fhNom:\n",
    "        next\n",
    "    \n",
    "    df = pd.read_csv(qFile, sep='\\t', low_memory=False)\n",
    "    print(os.path.basename(qFile))\n",
    "    if df.shape[0] < 10:\n",
    "        continue\n",
    "    header = [e.replace(':', '') for e in df.columns.values.tolist() ]\n",
    "    header = [e.replace('/', '') for e in header ]\n",
    "    header = [e.replace('^', '') for e in header ]\n",
    "    header = [e.replace('.', '') for e in header ]\n",
    "    header = [e.replace('Âµ', 'u') for e in header ]\n",
    "    header = [e.replace(' ', '_') for e in header ]\n",
    "    header = [e.replace('-02_', '_') for e in header ]\n",
    "    df.columns = header\n",
    "    df['ROI'] = [e.split(' - ')[0].replace('.ome.tiff', '') for e in df['Image'].tolist() ]\n",
    "    df['Slide'] = ['_'.join(e.split('_')[0:3]) for e in df['ROI'].tolist() ]\n",
    "    top = np.min(df['Centroid_Y_um']) + np.max(df['Centroid_Y_um'])\n",
    "    df['invertY'] = top - df['Centroid_Y_um']\n",
    "    print(\"    Resulting Shape: {} x {}\".format(df.shape[0], df.shape[1]))\n",
    "    nClass = df['Class'].astype(str).nunique()\n",
    "    print(\"    Unique Classifications: \"+str(nClass) )\n",
    "    keepDFList.append(df)\n",
    "\n",
    "allClassData = pd.concat(keepDFList)\n",
    "allClassData = allClassData[allClassData.columns.drop(list(allClassData.filter(regex='(_Variance|_Min|_Max|_Cytoplasm_)')))]\n",
    "allClassData['uuid'] = [uuid.uuid4() for _ in range(len(allClassData.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d86bf-103f-4857-a00c-b736cedb2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassData.loc[allClassData['Class'] == \"CD68\", 'Class'] = 'Macs'\n",
    "allClassData.loc[allClassData['Class'] == \"CD8/CD3\", 'Class'] = 'CD8 T'\n",
    "allClassData.loc[allClassData['Class'] == \"CD4/CD3\", 'Class'] = 'CD4 T'\n",
    "allClassData['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b50c1e-0328-404b-a6cf-0b18aba308f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassData.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2a6cf-0161-409a-b420-edde7e2d32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(allClassData['Slide'],allClassData['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b9e27-ab60-4489-9a74-0c0385947a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batching = allClassData.filter(regex='(_Mean|ROI)',axis=1)\n",
    "df_melted = pd.melt(df_batching, id_vars=[\"ROI\"])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(26,6))\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=65)\n",
    "sns.boxplot(x='ROI', y='value', data=df_melted, ax=ax1, showfliers = False).set(title='Total Protein Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa968d3-abe6-42ec-adfe-57cbfacccb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypingData = allClassData.copy(deep=True)\n",
    "keepCols = ['Class','ROI','Slide','Centroid_','uuid',\n",
    "            'NA1_Nucleus','NA2_Nucleus','SMA_Cell', 'CD19_Cell', 'CD20_Cell','Pan-Ker_Cell','CD11b_Cell', 'Vimentin_Membrane',\n",
    "            'CD45_Membrane','CD4_Cell','E_Cadherin_Cell','CD68_Cell','CD8a_Cell','CD3_Cell','cd14_Cell','Nak-ATPase_Membrane',\n",
    "            'Vista_Nucleus','CollagenI_Cell','CD45RO_Cell','_Length','_area_ratio']\n",
    "\n",
    "lst = \"(\"+'|'.join(keepCols)+\")\"\n",
    "phenotypingData = phenotypingData.filter(regex=lst,axis=1)\n",
    "print( ', '.join(phenotypingData.columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79546dd-c296-4820-a961-f795688e07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypingData[\"Class2\"] = phenotypingData[\"Class\"]\n",
    "minSD = abs(np.min(phenotypingData['NA1_Nucleus_StdDev']))+1\n",
    "minMn = abs(np.min(phenotypingData['NA1_Nucleus_Mean']))+1\n",
    "phenotypingData['NA1_Nucleus_Ratio'] = (phenotypingData['NA1_Nucleus_StdDev']+minSD)/(phenotypingData['NA1_Nucleus_Mean']+minMn)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.scatterplot(x = \"NA1_Nucleus_Mean\", y = \"NA1_Nucleus_StdDev\", data = phenotypingData,\n",
    "                hue = \"NA1_Nucleus_Ratio\", palette = \"coolwarm\", ax=ax)\n",
    "\n",
    "dapiSTDcutpoint1 = phenotypingData['NA1_Nucleus_Ratio'].quantile(0.9999) \n",
    "dapiSTDcutpoint2 = phenotypingData['NA1_Nucleus_Ratio'].quantile(0.0001)\n",
    "print(f\"High Ratio: {dapiSTDcutpoint1}\\nLow Ratio: {dapiSTDcutpoint2}\")\n",
    "\n",
    "## Dapi guided variablity likely indicating very poor segementation\n",
    "phenotypingData.loc[phenotypingData['NA1_Nucleus_Ratio'] > dapiSTDcutpoint1, 'Class2'] = 'ARTIFACT: DNA1 RATIO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece8d2d-3047-47b2-b46e-623d4d904269",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypingData[\"Class2\"] = phenotypingData[\"Class\"]\n",
    "minSD = abs(np.min(phenotypingData['NA2_Nucleus_StdDev']))+1\n",
    "minMn = abs(np.min(phenotypingData['NA2_Nucleus_Mean']))+1\n",
    "phenotypingData['NA2_Nucleus_Ratio'] = (phenotypingData['NA2_Nucleus_StdDev']+minSD)/(phenotypingData['NA2_Nucleus_Mean']+minMn)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "sns.scatterplot(x = \"NA2_Nucleus_Mean\", y = \"NA2_Nucleus_StdDev\", data = phenotypingData,\n",
    "                hue = \"NA2_Nucleus_Ratio\", palette = \"coolwarm\", ax=ax)\n",
    "\n",
    "dapiSTDcutpoint1 = phenotypingData['NA2_Nucleus_Ratio'].quantile(0.9999)\n",
    "dapiSTDcutpoint2 = phenotypingData['NA2_Nucleus_Ratio'].quantile(0.0001)\n",
    "print(f\"High Ratio: {dapiSTDcutpoint1}\\nLow Ratio: {dapiSTDcutpoint2}\")\n",
    "\n",
    "## Dapi guided variablity likely indicating very poor segementation\n",
    "phenotypingData.loc[phenotypingData['NA2_Nucleus_Ratio'] > dapiSTDcutpoint1, 'Class2'] = 'ARTIFACT: DNA2 RATIO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127b4ea-ee7c-4c77-b138-1cc1d76cffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find sum of columns specified\n",
    "meanMarkers = [x for x in phenotypingData if '_Mean' in x]\n",
    "phenotypingData['SigSum'] = phenotypingData[meanMarkers].sum(axis=1)\n",
    "SigSumcutpoint1 = phenotypingData['SigSum'].quantile(0.999)\n",
    "SigSumcutpoint2 = phenotypingData['SigSum'].quantile(0.0001)\n",
    "\n",
    "print(f\"High SigSum: {SigSumcutpoint1}\\nLow SigSum: {SigSumcutpoint2}\")\n",
    "\n",
    "phenotypingData.loc[phenotypingData['SigSum'] > SigSumcutpoint1, 'Class2'] = 'ARTIFACT: SIGSUM'\n",
    "phenotypingData.loc[phenotypingData['SigSum'] < SigSumcutpoint2, 'Class2'] = 'ARTIFACT: SIGSUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef3ee7-e2d0-419f-9077-d868416d52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(phenotypingData['Class2'],phenotypingData['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae2648-1bc4-45d8-bec2-6f6148b28403",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = phenotypingData['Class2'].value_counts()\n",
    "pt = phenotypingData['Class2'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n",
    "pd.concat([ct,pt], axis=1, keys=['counts', '%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3448819-bb61-4653-b333-a54efe973596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "secondNormalized = phenotypingData.copy(deep=True)\n",
    "secondNormalized = secondNormalized.loc[~secondNormalized['Class2'].str.contains(\"ARTIFACT: \", na=False)]\n",
    "secondNormalized.reset_index(drop=True, inplace=True)\n",
    "\n",
    "secondNormalized['_id'] = secondNormalized.index\n",
    "### Do Box Cox on batch\n",
    "tmp = secondNormalized.filter(regex='(_Median|_id)',axis=1)\n",
    "tmp2 = pd.melt(tmp, id_vars=['_id'])\n",
    "tmp2['value'] = (tmp2['value'] + 1)\n",
    "# box cox cannot handle values of zero\n",
    "nArr, mxLambda = boxcox(tmp2['value'].to_list())\n",
    "tmp2['valueBC'] = nArr\n",
    "tmp3 = tmp2[[\"_id\",\"variable\",\"valueBC\"]].pivot(columns=\"variable\", index=\"_id\", values='valueBC')\n",
    "\n",
    "secondNormalized.set_index('_id', inplace=True, drop=False)\n",
    "df_a = secondNormalized[secondNormalized.columns.difference(tmp3.columns)]\n",
    "dfBMSnorm = pd.concat([df_a, tmp3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fa151-a497-439c-ac11-8a766c38ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBMSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce2655-6df5-4901-a12a-b885ac66badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batching = dfBMSnorm.filter(regex='(_Median|ROI|Slide)',axis=1)\n",
    "df_melted = pd.melt(df_batching, id_vars=[\"ROI\",\"Slide\"])\n",
    "fig, ax1 = plt.subplots(figsize=(28,6))\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=45)\n",
    "sns.boxplot(x='ROI', y='value', hue=\"Slide\", data=df_melted, ax=ax1, showfliers = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165be517-c4c0-490d-9a1a-5cea561cc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dfBMSnorm.filter(regex='(_Mean)',axis=1)\n",
    "\n",
    "for clm in tmp.columns.values.tolist():\n",
    "    sFl = clm.replace('_Mean','_StdDev')\n",
    "    rto = clm.replace('_Mean','_Ratio')\n",
    "    dfBMSnorm[rto] = (dfBMSnorm[sFl]+1)/(dfBMSnorm[clm]+1)\n",
    "    dfBMSnorm[dfBMSnorm[rto] < 0] = 0\n",
    "\n",
    "dfBMSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36dfe9-ef2b-4bd6-94fa-4b1a1ee9e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub3 = dfBMSnorm.filter(regex='(_Median|_Ratio)',axis=1).sample(frac=0.01)\n",
    "sns.clustermap(data=sub3, yticklabels=False, cmap = \"coolwarm\", vmin= -2, vmax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadaaa4-faad-46eb-b2cb-0ca12900f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a scaler object\n",
    "scaler = StandardScaler()\n",
    "df_numerics_only = dfBMSnorm.filter(regex='(_Median|_Ratio|_id)',axis=1)\n",
    "df_norm = pd.DataFrame(scaler.fit_transform(df_numerics_only), columns=df_numerics_only.columns)\n",
    "df_a = dfBMSnorm[dfBMSnorm.columns.difference(df_numerics_only.columns)]\n",
    "dfStandardize = pd.concat([df_a.reset_index(drop=True), df_norm], axis=1)\n",
    "\n",
    "\n",
    "df_batching = dfStandardize.filter(regex='(_Median|ROI|Slide)',axis=1)\n",
    "df_melted = pd.melt(df_batching, id_vars=[\"ROI\",\"Slide\"])\n",
    "fig, ax1 = plt.subplots(figsize=(18,6))\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(),rotation=45)\n",
    "sns.boxplot(x='ROI', y='value', hue=\"Slide\", data=df_melted, ax=ax1, showfliers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c00265-aacb-44d2-85e5-3e71b99bdfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub3 = dfStandardize.filter(regex='(_Median|_Ratio)',axis=1).sample(frac=0.015)\n",
    "sns.clustermap(data=sub3, yticklabels=False, cmap = \"coolwarm\", vmin= -2, vmax=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e58d1-6342-41f1-928e-ee7a67fef2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tierOnePredict = dfStandardize.copy(deep=True)\n",
    "tierOnePredict = tierOnePredict[~tierOnePredict['Class'].isna()]\n",
    "# tierOnePredict.shape\n",
    "## split into predictor variables (X) and outcome variable (y)\n",
    "idx = tierOnePredict.columns.get_loc(\"Class\")\n",
    "y = tierOnePredict.iloc[:,idx]\n",
    "X = tierOnePredict.filter(regex='(_Membrane|_Cell)*(_Median|_Ratio|_Length_um)$',axis=1)\n",
    "pprint(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746ca48-7c26-4561-b4c7-12065f6146b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_round = 380\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_Encode = le.fit_transform(y)\n",
    "(unique, counts) = np.unique(y_Encode, return_counts=True)\n",
    "\n",
    "# read in data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_Encode, test_size=0.33)\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcd877-d555-463a-8627-df1c6095e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "# eta [default=0.3, alias: learning_rate]\n",
    "depthField = [4, 6, 8, 12, 16, 19]\n",
    "learnRates = [0.1, 0.25, 0.38, 0.5]\n",
    "metricModel = []\n",
    "\n",
    "for d in depthField:\n",
    "    for l in learnRates:\n",
    "        param = {'max_depth':d, 'eta': l, 'objective':'multi:softmax', 'n_jobs': 32,\n",
    "                 'num_class': len(unique), 'eval_metric': 'mlogloss' }\n",
    "        bst = xgb.train(param, dtrain, num_round)\n",
    "        \n",
    "        predTrain = bst.predict(dtrain) ## Exports lables of type Float\n",
    "        GBCmpredTrain = le.inverse_transform(np.array(predTrain, dtype=np.int))\n",
    "        yLabelTrain = le.inverse_transform(np.array(y_train, dtype=np.int)) \n",
    "        accuracyTrain = accuracy_score(yLabelTrain, GBCmpredTrain)\n",
    "    \n",
    "        preds = bst.predict(dtest) ## Exports lables of type Float\n",
    "        GBCmpred = le.inverse_transform(np.array(preds, dtype=np.int))\n",
    "        yLabelTest = le.inverse_transform(np.array(y_test, dtype=np.int)) \n",
    "        accuracy = accuracy_score(yLabelTest, GBCmpred)\n",
    "        metricModel.append({'max_depth':d, 'eta':l, 'Training': \"%.2f%%\" % (accuracyTrain * 100.0), \n",
    "                          'Test': \"%.2f%%\" % (accuracy * 100.0), 'testf':accuracy })\n",
    "\n",
    "xgboostParams = pd.DataFrame(metricModel)\n",
    "xgboostParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332eaa2e-2be3-41c8-b44a-101d60bcfc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = np.max(xgboostParams['testf'])\n",
    "rr = xgboostParams.loc[xgboostParams['testf'] == mx,]\n",
    "print(\"Max Test Accuracy: %.2f%%\" % (mx * 100.0) )\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce134a-205f-4217-b170-f40b6f46b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':4, 'eta': 0.38, 'objective':'multi:softmax', 'n_jobs': 32,\n",
    "                 'num_class': len(unique), 'eval_metric': 'mlogloss' }\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "    \n",
    "# make prediction\n",
    "predTrain = bst.predict(dtrain) ## Exports lables of type Float\n",
    "GBCmpredTrain = le.inverse_transform(np.array(predTrain, dtype=np.int))\n",
    "yLabelTrain = le.inverse_transform(np.array(y_train, dtype=np.int)) \n",
    "# evaluate predictions\n",
    "accuracyTrain = accuracy_score(yLabelTrain, GBCmpredTrain)\n",
    "print(\"Training Accuracy: %.2f%%\" % (accuracyTrain * 100.0))\n",
    "#print(pd.crosstab(GBCmpredTrain,yLabelTrain))\n",
    "#print(\"\\n\")\n",
    "# make prediction\n",
    "preds = bst.predict(dtest) ## Exports lables of type Float\n",
    "GBCmpred = le.inverse_transform(np.array(preds, dtype=np.int))\n",
    "yLabelTest = le.inverse_transform(np.array(y_test, dtype=np.int)) \n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(yLabelTest, GBCmpred)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "pd.crosstab(GBCmpred,yLabelTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58938e-9f07-4a0e-beb3-03dbd20cfc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = bst.get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.nlargest(25, columns=\"score\").plot(kind='barh', figsize = (9,12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6684871-8b7c-45e1-95c4-dfb5c67dacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xall = dfStandardize[X.columns.to_list()]\n",
    "xReal = xgb.DMatrix(Xall)\n",
    "\n",
    "realPred = bst.predict(xReal) ## Exports labels of type Float\n",
    "fullXGBPred = le.inverse_transform(np.array(realPred, dtype=np.int))\n",
    "\n",
    "dfStandardize['XGBoostPrediction'] = fullXGBPred.astype('str')\n",
    "\n",
    "nonBlank = dfStandardize.loc[pd.notna(dfStandardize[\"Class\"])]\n",
    "accuracy = accuracy_score(nonBlank[\"Class\"], nonBlank['XGBoostPrediction'])\n",
    "print(\"Total Model Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "pd.crosstab(nonBlank[\"Class\"], nonBlank['XGBoostPrediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8e9ae-ca4f-4b89-9d57-b51c449b409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(fullXGBPred).value_counts()\n",
    "pie, ax = plt.subplots(figsize=(11,10))\n",
    "labels = data.index\n",
    "ax.pie(x=data.values, autopct=\"%.1f%%\", explode=[0.05]*len(data), labels=labels, pctdistance=0.5)\n",
    "plt.title(\"XGBoosting Classifier\", fontsize=22);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365a7f5-6831-497b-9096-3a6b7816a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStandardize[\"PredMatch\"] = np.where(\n",
    "    (dfStandardize[\"XGBoostPrediction\"] == dfStandardize[\"Class\"]) & (pd.notna(dfStandardize[\"Class\"])), \"Y\", \"N\")\n",
    "\n",
    "dfStandardize[\"PredMatch\"] = np.where(pd.isna(dfStandardize[\"Class\"]), '-',dfStandardize[\"PredMatch\"])\n",
    "dfStandardize[\"PredMatch\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb93a18-1733-4568-bb76-7ffefbd0ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cscnts = pd.crosstab(dfStandardize['Slide'],dfStandardize[\"PredMatch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba59ef-ccad-45e8-8b91-0710cbd3d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cscnts = cscnts.loc[cscnts['N'] > 0]\n",
    "cscnts['pm'] = (cscnts['N'] / (cscnts['N']+cscnts['Y']))\n",
    "cscnts['PecentMissed'] = cscnts['pm'].mul(100).round(2).astype(str) + '%'\n",
    "cscnts.sort_values('pm', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6850b5-3f26-4135-8a95-413036efdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = dfStandardize['ROI'].unique().tolist()\n",
    "#random.shuffle(fovs)\n",
    "outCls = \"XGBoostPrediction\"\n",
    "t1Order = dfStandardize[outCls].unique().tolist()\n",
    "\n",
    "fov1 = dfStandardize.loc[dfStandardize['ROI'] == fovs[0]]\n",
    "fov2 = dfStandardize.loc[dfStandardize['ROI'] == fovs[1]]\n",
    "fov3 = dfStandardize.loc[dfStandardize['ROI'] == fovs[2]]\n",
    "fov4 = dfStandardize.loc[dfStandardize['ROI'] == fovs[3]]\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20,5))\n",
    "sns.scatterplot(data=fov1, x='Centroid_X_um', y='Centroid_Y_um', hue=outCls, ax=ax1, palette=\"Dark2\",\n",
    "                hue_order = t1Order, legend=False).set(title=fov1.iloc[1]['ROI'])\n",
    "sns.scatterplot(data=fov2, x='Centroid_X_um', y='Centroid_Y_um',hue=outCls, ax=ax2,  palette=\"Dark2\",\n",
    "                hue_order = t1Order, legend=False).set(title=fov2.iloc[1]['ROI'])\n",
    "sns.scatterplot(data=fov3, x='Centroid_X_um', y='Centroid_Y_um',hue=outCls, ax=ax3,  palette=\"Dark2\",\n",
    "                hue_order = t1Order, legend=False).set(title=fov3.iloc[1]['ROI'])\n",
    "sns.scatterplot(data=fov4, x='Centroid_X_um', y='Centroid_Y_um', hue=outCls, ax=ax4,  palette=\"Dark2\",\n",
    "                hue_order = t1Order, legend=False).set(title=fov4.iloc[1]['ROI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68819c9a-3e2b-4f3b-9199-9cbe988c80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStandardize['cnt'] = 1\n",
    "dfStandardize.groupby(['ROI', 'XGBoostPrediction']).agg({'cnt':\"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30a2fd-fb34-4584-b0bb-1f53c1a66f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put the skipped artifacts back in.\n",
    "subCols = dfStandardize.loc[:,['XGBoostPrediction','uuid']]\n",
    "mergeDF = pd.merge(phenotypingData, subCols, on=\"uuid\", how=\"left\")\n",
    "#mergeDF.loc[mergeDF['XGBoostPrediction'].isna(), 'XGBoostPrediction'] = 'Artifact'\n",
    "mergeDF['FinalClassify'] = mergeDF['XGBoostPrediction']\n",
    "mergeDF['FinalClassify'].fillna(mergeDF['Class2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac66439-13ea-4f4b-84d1-e5e2dd1fa370",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(mergeDF['Class2'],mergeDF['FinalClassify'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9887f2b-3265-43c1-bff6-c4e6795d5919",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectCols = [\"uuid\",\"Centroid_X_um\",\"Centroid_Y_um\",\"FinalClassify\"]\n",
    "outDir = r\"./QUANT_with_preds\"\n",
    "\n",
    "for f in fovs:\n",
    "    roiTbl = mergeDF.loc[mergeDF['ROI'] == f, selectCols] \n",
    "    outFh = os.path.join(outDir,f+\"_PRED.tsv\")\n",
    "    roiTbl.to_csv(outFh, sep=\"\\t\")\n",
    "    print(outFh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af57017-3e8c-469a-b497-259a8aef3693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoost (Local)",
   "language": "python",
   "name": "local-xgboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
