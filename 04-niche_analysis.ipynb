{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48dbc8-6e50-4974-b69f-ef49586fa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, random, math, time, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "import anndata as ad\n",
    "print(f\"anndata=={ad.__version__}\")\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "print(f\"squidpy=={sq.__version__}\")\n",
    "import scimap as sm\n",
    "print(f\"scimap=={sm.__version__}\")\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import iqr\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb5898-be51-44c6-95fd-46234f6fc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(f\"sklearn=={sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda4e6-8d0b-458b-ba00-e8fcc1c061ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassData = pd.read_csv(\"./allClassData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f4e93-a07a-49ff-ae7a-d5382fa19518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create AnnData object\n",
    "noBad = allClassData[~allClassData['Class'].str.contains(\"ARTIFACT: \", na=False)] # remove artifacts from allClassData\n",
    "singleJustVars = noBad.filter(regex='(_Cell_)',axis=1) # Get only markers\n",
    "singleJustVars = singleJustVars[singleJustVars.columns.drop(list(singleJustVars.filter(regex='(_Max|_Mean)')))] # Remove max and mean\n",
    "\n",
    "adata = ad.AnnData(singleJustVars) # create AnnData object\n",
    "adata.obs_names = [ str(e) for e in noBad['uuid'].to_list()] # Set observation names\n",
    "adata.var_names = singleJustVars.columns.to_list() # Set variable names\n",
    "adata.obsm={ \"spatial\": noBad[['Centroid_X_um','invertY']].to_numpy(), # Add coordinates\n",
    "             \"Nucleus_Area\" : noBad[['Nucleus_Area_um2']].to_numpy(), # Add nucleus area\n",
    "             \"Cell_Area\" : noBad[['Cell_Area_um2']].to_numpy() # Add cell area\n",
    "           }  \n",
    "adata.obs[\"cell_type\"] = pd.Categorical( noBad['Class'] ) # Add Class annotations\n",
    "adata.uns[\"Slide\"] = noBad[\"Slide\"] # Add Slide\n",
    "adata.obs[\"imageid\"] = pd.Categorical( noBad[\"ROI\"] ) # Add ROI number\n",
    "adata.obs[\"cohort_site\"] = pd.Categorical( noBad[\"Origin\"] )\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dec32c-6a6d-493e-a2a7-548d3cfac4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://scimap.xyz/tutorials/5-Simple_Spatial_Analysis/\n",
    "\n",
    "adata.obs[\"X\"] = adata.obsm['spatial'][:,0] \n",
    "adata.obs[\"Y\"] = adata.obsm['spatial'][:,1]\n",
    "\n",
    "start_time = time.time()\n",
    "# The function allows users to calculate the average shortest distance between phenotypes or clusters of interest (3D data supported).\n",
    "adata = sm.tl.spatial_distance (adata, \n",
    "                               x_coordinate='X', y_coordinate='Y', \n",
    "                               z_coordinate=None, \n",
    "                               phenotype='cell_type', \n",
    "                               subset=None, \n",
    "                               imageid='imageid', \n",
    "                               label='spatial_distance')\n",
    "print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e6a0d-9c01-4533-be9d-091e0e6a94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up Database entries\n",
    "allClassData['cnt'] = 1\n",
    "pivoted = allClassData.pivot(columns=\"Class\", values=\"cnt\")\n",
    "pivoted.fillna(0, inplace=True)\n",
    "cells = pd.concat([allClassData, pivoted], axis=1 )\n",
    "#cells\n",
    "print(\"cells Shape: {} x {}\".format(cells.shape[0], cells.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508bc2c-7eac-4c05-a6c1-dffe5e76d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(job,n_neighbors):\n",
    "    '''\n",
    "    For each region and each individual cell in dataset, return the indices of the nearest neighbors.\n",
    "    'job:  meta data containing the start time,index of region, region name, indices of region in original dataframe\n",
    "    n_neighbors:  the number of neighbors to find for each cell\n",
    "    '''\n",
    "    start_time,idx,tissue_name,indices = job\n",
    "    job_start = time.time()\n",
    "    print (\"Starting:\", str(idx+1)+'/'+str(len(exps)),': ' + exps[idx])\n",
    "\n",
    "    tissue = tissue_group.get_group(tissue_name)\n",
    "    to_fit = tissue.loc[indices][[X,Y]].values\n",
    "    fit = NearestNeighbors(n_neighbors=n_neighbors).fit(tissue[[X,Y]].values)\n",
    "    m = fit.kneighbors(to_fit)\n",
    "    m = m[0], m[1]\n",
    "    \n",
    "    #sort_neighbors\n",
    "    args = m[0].argsort(axis = 1)\n",
    "    add = np.arange(m[1].shape[0])*m[1].shape[1]\n",
    "    sorted_indices = m[1].flatten()[args+add[:,None]]\n",
    "\n",
    "    neighbors = tissue.index.values[sorted_indices]\n",
    "    end_time = time.time()\n",
    "    print (\"Finishing:\", str(idx+1)+\"/\"+str(len(exps)),\": \"+ exps[idx],end_time-job_start,end_time-start_time)\n",
    "    return neighbors.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12980a77-1ea6-4db2-a6b7-b7142de08720",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col = 'Class'\n",
    "ks = [25,50] # k=5 means it collects 5 nearest neighbors for each center cell\n",
    "X = 'Centroid_X_um'\n",
    "Y = 'invertY'\n",
    "reg = 'ROI' ## MUST BE CHARACTER COLUMN\n",
    "keep_cols = [X,Y,reg,cluster_col]\n",
    "\n",
    "#read in data and do some quick data rearrangement\n",
    "n_neighbors = max(ks)\n",
    "sum_cols = cells[cluster_col].unique()\n",
    "values = cells[sum_cols].values ## This is giving 14, should be only 7 -- intentionally created by concat\n",
    "# pprint([list(cells.columns),sum_cols,values, values.ndim, values.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52afeb-be70-4b59-a212-45ccd53a3aaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find windows for each cell in each tissue region\n",
    "tissue_group = cells[[X,Y,reg]].groupby(reg)\n",
    "exps = list(cells[reg].unique())\n",
    "#pprint(tissue_group.groups.items())\n",
    "tissue_chunks = [(time.time(),exps.index(t),t,a) for t,indices in tissue_group.groups.items() for a in np.array_split(indices,1)] \n",
    "tissues = [get_windows(job,n_neighbors) for job in tissue_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d980bc-081f-41db-b70b-4a8ba4cb2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each cell and its nearest neighbors, reshape and count the number of each cell type in those neighbors.\n",
    "out_dict = {}\n",
    "for k in ks:\n",
    "    for neighbors,job in zip(tissues,tissue_chunks):\n",
    "        chunk = np.arange(len(neighbors))#indices\n",
    "        tissue_name = job[2]\n",
    "        indices = job[3]\n",
    "        window = values[neighbors[chunk,:k].flatten()].reshape(len(chunk),k,len(sum_cols)).sum(axis = 1)\n",
    "        out_dict[(tissue_name,k)] = (window.astype(np.float16),indices)\n",
    "\n",
    "#concatenate the summed windows and combine into one dataframe for each window size tested.\n",
    "windows = {}\n",
    "for k in ks:\n",
    "    window = pd.concat([pd.DataFrame(out_dict[(exp,k)][0],index = out_dict[(exp,k)][1].astype(int),columns = sum_cols) for exp in exps],0)\n",
    "    window = window.loc[cells.index.values]\n",
    "    window = pd.concat([cells[keep_cols],window],1)\n",
    "    windows[k] = window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416d649-c5ab-4416-8e46-285d45d13717",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "n_neighborhoods = 9\n",
    "neighborhood_name = \"neighborhood\"+str(k)\n",
    "k_centroids = {}\n",
    "print(\"k = \"+str(k)+\",  Communities = \"+str(n_neighborhoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f289fc0-7879-4d0b-a8ad-5d6b1cb01a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows2 = windows[k]\n",
    "# windows2[cluster_col] = cells[cluster_col]\n",
    "km = MiniBatchKMeans(n_clusters = n_neighborhoods,random_state=0,n_init=3)\n",
    "labelskm = km.fit_predict(windows2[sum_cols].values)\n",
    "k_centroids[k] = km.cluster_centers_\n",
    "cells[neighborhood_name] = labelskm\n",
    "cells[neighborhood_name] = cells[neighborhood_name].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be578d-4b6e-46fb-867a-e63d4f922fd2",
   "metadata": {},
   "source": [
    "### Clusters - Proportions of Cell Types w/in a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b3486-821f-45d4-941e-3d05ed303a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedvalues=cells.groupby(neighborhood_name).sum().reset_index()\n",
    "gShort = groupedvalues[[neighborhood_name,'cnt']]\n",
    "aggDF = cells.groupby([neighborhood_name,cluster_col]).size().reset_index()\n",
    "\n",
    "merged_data= aggDF.merge(gShort, on=[neighborhood_name,neighborhood_name])\n",
    "merged_data['percent'] = merged_data[0] / merged_data['cnt']\n",
    "merged_data = merged_data.sort_values([neighborhood_name, \"percent\"], ascending = (True, False))\n",
    "\n",
    "fltrDF = merged_data[merged_data['percent'] >= 0.1]\n",
    "lastClst = '0'\n",
    "namedClusters = {}\n",
    "for index, row in fltrDF.iterrows():\n",
    "    if lastClst != row[neighborhood_name]:\n",
    "       # print(\"\")\n",
    "        namedClusters[row[neighborhood_name]] = [ \"{:.0%} {}\".format(row['percent'], row[cluster_col]) ]\n",
    "    else:\n",
    "        namedClusters[row[neighborhood_name]].append( \"{:.0%} {}\".format(row['percent'], row[cluster_col]) )\n",
    "    print(\"Cluster {} contains {:.0%} {}\".format(row[neighborhood_name], row['percent'], row[cluster_col]))\n",
    "    lastClst = row[neighborhood_name]\n",
    "\n",
    "for key, value in namedClusters.items():\n",
    "    tmp = ', '.join(value).replace(' Cells','').replace(' Cell','')\n",
    "    namedClusters[key] = \"#\"+str(key)+\": \"+tmp\n",
    "    \n",
    "#pprint(namedClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d04efc-c9d4-49da-83a5-77b69b6d7c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "merged_data # \n",
    "md2 = merged_data[['neighborhood50', 'Class', 0]]\n",
    "md2 = np.log2(md2.pivot(index='neighborhood50', columns='Class')[0]+0.00001)\n",
    "md2['ClusterNames'] = md2.index.map(namedClusters)\n",
    "md2.set_index('ClusterNames', inplace=True)\n",
    "sns.clustermap(md2, cmap = 'YlOrBr',row_cluster = True, col_cluster = False, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95609f45-453c-419d-88da-4f62369d204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customPalette = sns.set_palette(sns.color_palette( [\"#e31a1c\", \"#fb9a99\", \"#b2df8a\", \"#d9c0b0\",\n",
    "                                                    \"#1f78b4\", \"#cab2d6\", \"#33a02c\", \"#b15928\",\n",
    "                                                    \"#fa7270\"] ))\n",
    "\n",
    "plt.figure(figsize=[7,6])\n",
    "g=sns.barplot(y=neighborhood_name, x='cnt', data=groupedvalues, palette=customPalette)\n",
    "for index, row in groupedvalues.iterrows():\n",
    "    g.text( row.cnt, row.name, round(row.cnt), color='black', ha=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1823f2-7aea-4062-bb4f-8cb9281a8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells[neighborhood_name] = cells[neighborhood_name].astype('category')\n",
    "\n",
    "grps = cells[\"Cohort\"].dropna().unique().tolist()\n",
    "sts = cells[\"SiteLoc\"].dropna().unique().tolist()\n",
    "sts = [item for item in sts if item != 'NA']\n",
    "\n",
    "pprint([grps,sts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec2719-f888-4a4b-97f7-3e86287032b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp1 = cells[(cells['Cohort']==grps[0]) & (cells['SiteLoc']==sts[0])]\n",
    "lm = sns.lmplot(data = gp1, x = X, y=Y ,hue = neighborhood_name,palette = customPalette,\n",
    "           height = 10,col = reg,col_wrap = 5,fit_reg = False)\n",
    "fig = lm.fig \n",
    "# Add a title to the Figure\n",
    "fig.suptitle(\"FOVs from {} - {}\".format(grps[0],sts[0]), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba38f47-0f88-423f-8527-0db755de0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp1 = cells[(cells['Cohort']==grps[1]) & (cells['SiteLoc']==sts[0])]\n",
    "lm = sns.lmplot(data = gp1, x = X, y=Y ,hue = neighborhood_name,palette = customPalette,\n",
    "           height = 10,col = reg,col_wrap = 5,fit_reg = False)\n",
    "fig = lm.fig \n",
    "# Add a title to the Figure\n",
    "fig.suptitle(\"FOVs from {} - {}\".format(grps[1],sts[0]), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e66b6-b366-4c02-a053-a5a8e6bbd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp1 = cells[(cells['Cohort']==grps[0]) & (cells['SiteLoc']==sts[1])]\n",
    "lm = sns.lmplot(data = gp1, x = X, y=Y ,hue = neighborhood_name,palette = customPalette,\n",
    "           height = 10,col = reg,col_wrap = 5,fit_reg = False)\n",
    "fig = lm.fig \n",
    "# Add a title to the Figure\n",
    "fig.suptitle(\"FOVs from {} - {}\".format(grps[0],sts[1]), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85a2c9-ea5c-4ec5-938d-529b58588f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp1 = cells[(cells['Cohort']==grps[1]) & (cells['SiteLoc']==sts[1])]\n",
    "lm = sns.lmplot(data = gp1, x = X, y=Y ,hue = neighborhood_name,palette = customPalette,\n",
    "           height = 10,col = reg,col_wrap = 5,fit_reg = False)\n",
    "fig = lm.fig \n",
    "# Add a title to the Figure\n",
    "fig.suptitle(\"FOVs from {} - {}\".format(grps[1],sts[1]), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63271faf-9f11-4c3b-bcbd-2fc9e3bc55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells['Cohort2'] = cells['Cohort'] + \"-\" + cells['SiteLoc']\n",
    "\n",
    "# Set the context and style, and scale the font size\n",
    "sns.set(context=\"notebook\", font_scale=1.5, style = \"white\")\n",
    "# Set the custom palette for the current plot\n",
    "sns.set_palette(sns.color_palette([\"#E86EA6\", \"#9E1A1A\", \"#39BADA\", \"#162ABF\"]))\n",
    "\n",
    "#plot for each group and each patient the percent of total cells allocated to each neighborhood\n",
    "fc2 = cells.groupby(['Slide','Cohort2']).apply(lambda x: x[neighborhood_name].value_counts(sort = False,normalize = True))\n",
    "\n",
    "fc2.columns = range(n_neighborhoods)\n",
    "melt = pd.melt(fc2.reset_index(),id_vars = ['Slide','Cohort2'])\n",
    "melt = melt.rename(columns = {'variable':'community','value':'frequency of communities'})\n",
    "f,ax = plt.subplots(figsize = (16,9))\n",
    "sns.stripplot(data = melt, hue = 'Cohort2',dodge = True,alpha = .4,x ='community', y ='frequency of communities')\n",
    "sns.pointplot(data = melt, scatter_kws  = {'marker': 'd'},hue = 'Cohort2',dodge = .5,join = False,x ='community', y ='frequency of communities')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[:4], labels[:4], title=\"Clinical Group\",\n",
    "          handletextpad=0, columnspacing=1,\n",
    "          loc=\"upper right\", ncol=2, frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbaac8-bf5b-4eab-852f-111ef4dce04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells.to_csv(\"./cells_9neighborhood.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial_env (Local)",
   "language": "python",
   "name": "local-spatial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
